{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# === Cell 1: Setup & Imports ===\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\n\n# reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# allow GPU memory growth\nfor gpu in tf.config.list_physical_devices('GPU'):\n    tf.config.experimental.set_memory_growth(gpu, True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T02:37:47.184515Z","iopub.execute_input":"2025-04-17T02:37:47.184799Z","iopub.status.idle":"2025-04-17T02:38:05.256532Z","shell.execute_reply.started":"2025-04-17T02:37:47.184769Z","shell.execute_reply":"2025-04-17T02:38:05.255699Z"}},"outputs":[{"name":"stderr","text":"2025-04-17 02:37:52.026307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744857472.229529      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744857472.286253      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# === Cell 2: Paths & DataFrame Preparation ===\nTRAIN_DIR  = '/kaggle/input/histopathologic-cancer-detection/train'\nTEST_DIR   = '/kaggle/input/histopathologic-cancer-detection/test'\nLABELS_CSV = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\n\n# read labels and add filename column\ndf = pd.read_csv(LABELS_CSV)\ndf['filename'] = df['id'] + '.tif'\n\n# check dataset mounting\nprint(\"Number of train images:\", len(os.listdir(TRAIN_DIR)))\nprint(\"Number of test images: \", len(os.listdir(TEST_DIR)))\nprint(\"Sample train file exists:\", os.path.exists(os.path.join(TRAIN_DIR, df['filename'].iloc[0])))\n\n# stratified train/validation split (80/20)\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, stratify=df['label'], random_state=SEED\n)\nprint(f\"Train samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n\n# image parameters\nIMG_SIZE = 96\nBATCH    = 32\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T02:38:08.551274Z","iopub.execute_input":"2025-04-17T02:38:08.552021Z","iopub.status.idle":"2025-04-17T02:38:10.876691Z","shell.execute_reply.started":"2025-04-17T02:38:08.551971Z","shell.execute_reply":"2025-04-17T02:38:10.875541Z"}},"outputs":[{"name":"stdout","text":"Number of train images: 220025\nNumber of test images:  57458\nSample train file exists: True\nTrain samples: 176020, Validation samples: 44005\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# === Cell 3: Generator Sanity‑check (Small Sample) ===\n# sample a small balanced subset for quick test\nSAMPLE_N    = 2000\ntrain_small = train_df.groupby('label').sample(n=SAMPLE_N//2, random_state=SEED)\nval_small   = val_df  .groupby('label').sample(n=SAMPLE_N//2, random_state=SEED)\n\ndgen = ImageDataGenerator(rescale=1./255)\ngen_sm = dgen.flow_from_dataframe(\n    dataframe   = train_small,\n    directory   = TRAIN_DIR,\n    x_col       = 'filename',\n    y_col       = 'label',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    class_mode  = 'raw',\n    batch_size  = BATCH,\n    shuffle     = True,\n)\n\n# fetch one batch and inspect shapes\nx_batch, y_batch = next(gen_sm)\nprint(\"x_batch.shape:\", x_batch.shape)  # expected (BATCH, IMG_SIZE, IMG_SIZE, 3)\nprint(\"y_batch.shape:\", y_batch.shape)  # expected (BATCH,)\nprint(\"y_batch sample:\", y_batch[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T02:38:25.259878Z","iopub.execute_input":"2025-04-17T02:38:25.260204Z","iopub.status.idle":"2025-04-17T02:38:29.738182Z","shell.execute_reply.started":"2025-04-17T02:38:25.260180Z","shell.execute_reply":"2025-04-17T02:38:29.737453Z"}},"outputs":[{"name":"stdout","text":"Found 2000 validated image filenames.\nx_batch.shape: (32, 96, 96, 3)\ny_batch.shape: (32,)\ny_batch sample: [1 0 1 0 1 1 0 1 0 1]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# === Cell 4: Baseline CNN on Small Sample ===\ndef build_baseline():\n    model = models.Sequential([\n        layers.Input((IMG_SIZE, IMG_SIZE, 3)),\n        layers.Conv2D(32, 3, activation='relu', padding='same'), layers.MaxPooling2D(),\n        layers.Conv2D(64, 3, activation='relu', padding='same'), layers.MaxPooling2D(),\n        layers.Conv2D(128, 3, activation='relu', padding='same'), layers.MaxPooling2D(),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'), layers.Dropout(0.3),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n# build and train on the small subset\nbaseline = build_baseline()\nhistory_sm = baseline.fit(\n    gen_sm,\n    validation_data=dgen.flow_from_dataframe(\n        val_small, TRAIN_DIR, x_col='filename', y_col='label',\n        target_size=(IMG_SIZE, IMG_SIZE), class_mode='raw',\n        batch_size=BATCH, shuffle=False\n    ),\n    epochs=3,\n    verbose=2\n)\n\n# evaluate on small subset\npreds_sm = baseline.predict(gen_sm).ravel()\nauc_sm = roc_auc_score(train_small['label'], preds_sm[:len(train_small)])\nprint(\"Small-sample ROC AUC:\", auc_sm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T02:38:40.728602Z","iopub.execute_input":"2025-04-17T02:38:40.729257Z","iopub.status.idle":"2025-04-17T02:39:30.859422Z","shell.execute_reply.started":"2025-04-17T02:38:40.729217Z","shell.execute_reply":"2025-04-17T02:39:30.858382Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1744857520.868782      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Found 2000 validated image filenames.\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1744857531.695463      94 service.cc:148] XLA service 0x7ae118006010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1744857531.696232      94 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1744857532.072230      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1744857534.865927      94 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"63/63 - 30s - 473ms/step - accuracy: 0.6600 - loss: 0.6085 - val_accuracy: 0.7615 - val_loss: 0.5050\nEpoch 2/3\n63/63 - 5s - 83ms/step - accuracy: 0.7940 - loss: 0.4760 - val_accuracy: 0.7670 - val_loss: 0.5223\nEpoch 3/3\n63/63 - 5s - 80ms/step - accuracy: 0.7535 - loss: 0.5025 - val_accuracy: 0.7645 - val_loss: 0.4998\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step\nSmall-sample ROC AUC: 0.502706\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# === Cell 5: Baseline CNN on Full Data ===\n# prepare full-data generators\nfull_train_gen = dgen.flow_from_dataframe(\n    train_df, TRAIN_DIR, x_col='filename', y_col='label',\n    target_size=(IMG_SIZE, IMG_SIZE), class_mode='raw',\n    batch_size=BATCH, shuffle=True\n)\nfull_val_gen = dgen.flow_from_dataframe(\n    val_df, TRAIN_DIR, x_col='filename', y_col='label',\n    target_size=(IMG_SIZE, IMG_SIZE), class_mode='raw',\n    batch_size=BATCH, shuffle=False\n)\n\n# train baseline model\nbaseline = build_baseline()\nhistory_full = baseline.fit(\n    full_train_gen,\n    validation_data=full_val_gen,\n    epochs=5,\n    callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)],\n    verbose=2\n)\n\n# evaluate\nval_preds_full = baseline.predict(full_val_gen).ravel()\nval_auc_full    = roc_auc_score(val_df['label'], val_preds_full)\nprint(\"Final Baseline ROC AUC:\", val_auc_full)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T03:31:28.760362Z","iopub.execute_input":"2025-04-17T03:31:28.760708Z","iopub.status.idle":"2025-04-17T03:57:32.978600Z","shell.execute_reply.started":"2025-04-17T03:31:28.760682Z","shell.execute_reply":"2025-04-17T03:57:32.977796Z"}},"outputs":[{"name":"stdout","text":"Found 176020 validated image filenames.\nFound 44005 validated image filenames.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"5501/5501 - 285s - 52ms/step - accuracy: 0.8175 - loss: 0.4091 - val_accuracy: 0.8466 - val_loss: 0.3503\nEpoch 2/5\n5501/5501 - 276s - 50ms/step - accuracy: 0.8736 - loss: 0.3051 - val_accuracy: 0.8772 - val_loss: 0.2951\nEpoch 3/5\n5501/5501 - 284s - 52ms/step - accuracy: 0.8930 - loss: 0.2638 - val_accuracy: 0.8992 - val_loss: 0.2550\nEpoch 4/5\n5501/5501 - 278s - 51ms/step - accuracy: 0.9058 - loss: 0.2368 - val_accuracy: 0.9066 - val_loss: 0.2387\nEpoch 5/5\n5501/5501 - 278s - 51ms/step - accuracy: 0.9163 - loss: 0.2126 - val_accuracy: 0.9046 - val_loss: 0.2342\n\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 40ms/step\nFinal Baseline ROC AUC: 0.9664226137262383\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === Cell 6: Transfer Learning with EfficientNetB0 ===\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import layers, models, callbacks\n\n# 1) Create augmented training generator\ntrain_aug = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    horizontal_flip=True,\n    vertical_flip=True,\n    brightness_range=(0.8, 1.2)\n)\ntrain_gen = train_aug.flow_from_dataframe(\n    dataframe   = train_df,\n    directory   = TRAIN_DIR,\n    x_col       = 'filename',\n    y_col       = 'label',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    class_mode  = 'raw',\n    batch_size  = BATCH,\n    shuffle     = True\n)\n\n# 2) Create validation generator (no augmentation)\nval_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n    dataframe   = val_df,\n    directory   = TRAIN_DIR,\n    x_col       = 'filename',\n    y_col       = 'label',\n    target_size = (IMG_SIZE, IMG_SIZE),\n    class_mode  = 'raw',\n    batch_size  = BATCH,\n    shuffle     = False\n)\n\n# 3) Build the transfer‑learning model\nbase_model = EfficientNetB0(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n)\nbase_model.trainable = False  # freeze backbone\n\ntl_model = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.3),\n    layers.Dense(128, activation='swish'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid')\n])\ntl_model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# 4) Prepare callbacks (must save as .keras)\ncheckpoint = callbacks.ModelCheckpoint(\n    'best_efficient.keras',     # <— ends with .keras\n    monitor='val_loss',\n    save_best_only=True\n)\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=2,\n    min_lr=1e-6\n)\n\n# 5) Train the head layers\ntl_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5,\n    callbacks=[checkpoint, reduce_lr],\n    verbose=2\n)\n\n# 6) Unfreeze the backbone for fine‑tuning\nbase_model.trainable = True\ntl_model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\ntl_model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5,\n    callbacks=[checkpoint, reduce_lr],\n    verbose=2\n)\n\n# 7) Load the best weights and evaluate\ntl_model.load_weights('best_efficient.keras')\nval_preds_tl = tl_model.predict(val_gen).ravel()\nprint(\"Transfer Learning ROC AUC:\", roc_auc_score(val_df['label'], val_preds_tl))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:12:55.619850Z","iopub.execute_input":"2025-04-17T04:12:55.620195Z"}},"outputs":[{"name":"stdout","text":"Found 176020 validated image filenames.\nFound 44005 validated image filenames.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"5501/5501 - 796s - 145ms/step - accuracy: 0.5943 - loss: 0.6771 - val_accuracy: 0.5950 - val_loss: 0.6749 - learning_rate: 0.0010\nEpoch 2/5\n5501/5501 - 773s - 140ms/step - accuracy: 0.5947 - loss: 0.6754 - val_accuracy: 0.5950 - val_loss: 0.6750 - learning_rate: 0.0010\nEpoch 3/5\n5501/5501 - 767s - 139ms/step - accuracy: 0.5949 - loss: 0.6751 - val_accuracy: 0.5950 - val_loss: 0.6750 - learning_rate: 0.0010\nEpoch 4/5\n5501/5501 - 772s - 140ms/step - accuracy: 0.5950 - loss: 0.6750 - val_accuracy: 0.5950 - val_loss: 0.6748 - learning_rate: 5.0000e-04\nEpoch 5/5\n5501/5501 - 767s - 139ms/step - accuracy: 0.5950 - loss: 0.6750 - val_accuracy: 0.5950 - val_loss: 0.6747 - learning_rate: 5.0000e-04\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1744867232.545466      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867232.728251      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867233.227215      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867233.417614      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867233.705380      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867233.921825      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867234.318426      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867234.508717      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867234.766663      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867234.983730      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867634.166895      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867634.351328      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867634.934905      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867635.128205      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867635.412027      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867635.628543      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867636.128495      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867636.321569      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867636.588725      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1744867636.805324      94 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"5501/5501 - 936s - 170ms/step - accuracy: 0.7595 - loss: 0.8462 - val_accuracy: 0.8380 - val_loss: 0.4238 - learning_rate: 1.0000e-05\nEpoch 2/5\n5501/5501 - 792s - 144ms/step - accuracy: 0.8306 - loss: 0.4230 - val_accuracy: 0.8620 - val_loss: 0.3302 - learning_rate: 1.0000e-05\nEpoch 3/5\n5501/5501 - 794s - 144ms/step - accuracy: 0.8611 - loss: 0.3367 - val_accuracy: 0.8888 - val_loss: 0.2762 - learning_rate: 1.0000e-05\nEpoch 4/5\n5501/5501 - 799s - 145ms/step - accuracy: 0.8825 - loss: 0.2967 - val_accuracy: 0.8986 - val_loss: 0.2561 - learning_rate: 1.0000e-05\nEpoch 5/5\n5501/5501 - 813s - 148ms/step - accuracy: 0.8946 - loss: 0.2667 - val_accuracy: 0.9075 - val_loss: 0.2355 - learning_rate: 1.0000e-05\n\u001b[1m 623/1376\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 43ms/step","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# === Cell 7: Test Prediction & Submission ===\ntest_files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith('.tif')])\ntest_df    = pd.DataFrame({'filename': test_files})\n\ntest_gen = dgen.flow_from_dataframe(\n    test_df, TEST_DIR, x_col='filename', y_col=None,\n    target_size=(IMG_SIZE, IMG_SIZE), class_mode=None,\n    batch_size=BATCH, shuffle=False\n)\n\npredictions = tl_model.predict(test_gen, verbose=1).ravel()\nsubmission  = pd.DataFrame({\n    'id':    [f.replace('.tif','') for f in test_files],\n    'label': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv has been created.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T06:38:42.326211Z","iopub.execute_input":"2025-04-17T06:38:42.326474Z","iopub.status.idle":"2025-04-17T06:40:23.930556Z","shell.execute_reply.started":"2025-04-17T06:38:42.326454Z","shell.execute_reply":"2025-04-17T06:40:23.929806Z"}},"outputs":[{"name":"stdout","text":"Found 57458 validated image filenames.\n\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 41ms/step\nsubmission.csv has been created.\n","output_type":"stream"}],"execution_count":13}]}